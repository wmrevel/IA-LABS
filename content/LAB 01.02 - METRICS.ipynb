{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wmrevel/IA-LABS/blob/main/content/LAB%2001.02%20-%20METRICS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLaCVts8R4aM"
      },
      "source": [
        "# LAB 01.02 - Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-0s9bJoR4aQ"
      },
      "outputs": [],
      "source": [
        "!wget --no-cache -O init.py -q https://raw.githubusercontent.com/rramosp/ai4eng.v1/main/content/init.py\n",
        "import init, inspect; init.init(force_download=False); init.get_weblink()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuBdWSRvR4aT"
      },
      "outputs": [],
      "source": [
        "from local.lib.rlxmoocapi import submit, session\n",
        "session.LoginSequence(endpoint=init.endpoint, course_id=init.course_id, lab_id=\"L01.02\", varname=\"student\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2g6ln5eR4aU"
      },
      "source": [
        "## General remark\n",
        "\n",
        "You do not need to use Python to solve the problems in this notebook, you can use any tool of your choice (Excel, etc.), including **pen and paper**. But\n",
        "\n",
        "### If you want to try out in Python\n",
        "\n",
        "- `numpy` is the Python library used for vectors\n",
        "- there are operations that take a vector and produce another vector (i.e. `np.log`)\n",
        "- there are operations that take a vector and procude a number (i.e. `np.mean`)\n",
        "- there are operations that take two vectors and produce a number (see the **HINTs** below)\n",
        "- etc.\n",
        "\n",
        "For instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "3TxtQvAjR4aW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "v1 = np.array([1,2,3,4])\n",
        "\n",
        "# the log of each element of the vector\n",
        "print ( \"the log   =\", np.log(v1)  )\n",
        "\n",
        "# the mean of all elements of the vector\n",
        "print ( \"the mean  =\",  np.mean(v1)  )\n",
        "\n",
        "# multiply all elements of a vector with a scalar\n",
        "print (\"times two =\", 2*v1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVeIMAk4R4aX"
      },
      "source": [
        "you can always check the type of any variable "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3dHX-idR4aY"
      },
      "outputs": [],
      "source": [
        "a = 2.0\n",
        "type(v1), type(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wop6PBMnR4aZ"
      },
      "source": [
        "## Task 01. Accuracy\n",
        "\n",
        "Compute the percentage of correct predictions **accuracy** (see [here](https://en.wikipedia.org/wiki/Sensitivity_and_specificity#Definitions)) for the following model output (`predicted`) and ground truth (`actual`).\n",
        "\n",
        "Execute the following cell to generate the data from which you must compute the metric. You may compute the metric implementing python code, or manually, or copy/pasting the actual and predicted data in Excel, etc.\n",
        "\n",
        "**CHALLENGE**: use Python with [`sklearn.metrics.accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score)\n",
        "\n",
        "\n",
        "Observe that every time you execute the following cell, **a different set of values** is generated. You will have to compute the metric **for the values that you see**. If you run the cell again you will have to compute your metric value again."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agregar librería sklearn para utilizar la función accuracy"
      ],
      "metadata": {
        "id": "8hoSzjehSfu4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4Gs7yFJR4ab",
        "outputId": "e08147c5-a4f8-4c5f-d886-ab7e5a2c9f2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "actual    0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1\n",
            "predicted 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "t1_actual    = np.random.randint(2, size=20)\n",
        "t1_predicted = np.abs(t1_actual*(np.random.random(size=20)>(np.random.random()*.9+.05)).astype(int))\n",
        "print (\"actual   \", \", \".join([str(i) for i in t1_actual]))\n",
        "print (\"predicted\", \", \".join([str(i) for i in t1_predicted]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKqJenT1R4ac"
      },
      "source": [
        "Assign the value of your computation to the `accuracy` variable, **with three decimal places**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Función accuracy_score"
      ],
      "metadata": {
        "id": "jkBZ10bIS3sF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuEsijNcR4ae",
        "outputId": "cdb6157d-603c-4385-8086-d15508dd3ae0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "accuracy = accuracy_score(t1_actual,t1_predicted)\n",
        "accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsLVxV0YR4af"
      },
      "source": [
        "#### submit your answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgxJc3WhR4ag"
      },
      "outputs": [],
      "source": [
        "student.submit_task(globals(), task_id=\"task_01\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOB45HyWR4ah"
      },
      "source": [
        "## Task 2: Sensitivity\n",
        "\n",
        "Compute the sensitivity metric [aka the _True Positive Rate_ or _Recall_ see [Sensitivity on Wikipedia](https://en.wikipedia.org/wiki/Sensitivity_and_specificity)] for the following model output (`predicted`) and ground truth (`actual`)\n",
        "\n",
        "Execute the following cell to generate the data from which you must compute the metric. You may compute the metric implementing python code, or manually, or copy/pasting the actual and predicted data in Excel, etc.\n",
        "\n",
        "**Challenge**: Use Python [`sklearn.metrics.recall_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html)\n",
        "\n",
        "\n",
        "Observe that every time you execute the following cell, **a different set of values** is generated. You will have to compute the metric **for the values that you see**. If you run the cell again you will have to compute your metric value again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0P3L4o3dR4ai",
        "outputId": "c9601484-a0e2-4c71-ab5b-d921e10bf6b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "actual    0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0\n",
            "predicted 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import recall_score\n",
        "t2_predicted = np.random.randint(2, size=20)\n",
        "t2_actual = np.random.randint(2, size=20)\n",
        "t2_predicted[np.argwhere(t2_actual==1)[0][0]]=0\n",
        "print (\"actual   \", \", \".join([str(i) for i in t2_actual]))\n",
        "print (\"predicted\", \", \".join([str(i) for i in t2_predicted]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaQCFxZtR4ak"
      },
      "source": [
        "Assign the value of your computation to the `tpr` variable **with three decimal places**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXpU6n9fR4al",
        "outputId": "fb13455a-5b99-458e-8ee0-5493e5db0fb0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "tpr = recall_score(t2_actual,t2_predicted)\n",
        "tpr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKwM_ps3R4am"
      },
      "source": [
        "#### submit your answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "r4jGYkrpR4an"
      },
      "outputs": [],
      "source": [
        "student.submit_task(globals(), task_id=\"task_02\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDGEQBgeR4ao"
      },
      "source": [
        "## Task 3: Evaluation in New York City Taxi Trip Duration Kaggle Competition\n",
        "\n",
        "Understand the data and the evaluation metric (**Root Mean Squared Logarithmic Error**, RMSLE) of the following Kaggle competition\n",
        "\n",
        "- [https://www.kaggle.com/c/nyc-taxi-trip-duration/](https://www.kaggle.com/c/nyc-taxi-trip-duration/)\n",
        "\n",
        "Observe that this competition is a **regression task** as we are measuring the difference in prediction with respect to the actual.\n",
        "\n",
        "For instance, the following model predictions and ground truth:\n",
        "\n",
        "    actual    [66 37 22]\n",
        "    predicted [79 51 67]\n",
        "    \n",
        "produce a **RMSLE** of 0.66 aprox.\n",
        "\n",
        "Execute the following cell to generate the data from which you must compute the metric. You may compute the metric implementing python code, or manually, or copy/pasting the actual and predicted data in Excel, etc.\n",
        "\n",
        "**Challenge**: For python use numpy function `np.log` or `np.log1p`\n",
        "\n",
        "Observe that every time you execute the following cell, **a different set of values** is generated. You will have to compute the metric **for the values that you see**. If you run the cell again you will have to compute your metric value again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSjShsqXR4ap",
        "outputId": "7f6bac68-66d4-4727-e8dd-ed81a7d295b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "actual    [96 96 76 29 83 65 66 90 48 96 26 26 20 73 32]\n",
            "predicted [85 31 67 80 68 85 98 53 95 62 80 59 67 87 64]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_log_error\n",
        "t3_actual    = np.random.randint(80,size=15)+20\n",
        "t3_predicted = np.random.randint(80,size=15)+20\n",
        "print (\"actual   \", t3_actual)\n",
        "print (\"predicted\", t3_predicted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yf3FLQyQR4aq"
      },
      "source": [
        "Assign the value of your computation to the `rmsle` variable **with three decimal places**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0jJ8X16R4aq",
        "outputId": "0e23f10d-f71a-4f09-c1f0-f76c6d879968"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6895943902282751"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "\n",
        "rmsle = np.sqrt(mean_squared_log_error(t3_actual,t3_predicted))\n",
        "rmsle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0K2MchsR4ar"
      },
      "source": [
        "#### submit your answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "qkGdXZ0zR4as"
      },
      "outputs": [],
      "source": [
        "student.submit_task(globals(), task_id=\"task_03\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGuny64gR4as"
      },
      "source": [
        "## Task 4: Evaluation in Shelter Animal Outcomes Kaggle Competition\n",
        "\n",
        "Understand the data and the evaluation metric (**Multiclass Logaritmic Loss**, _logloss_) of the following Kaggle competition\n",
        "\n",
        "- [https://www.kaggle.com/c/shelter-animal-outcomes/](https://www.kaggle.com/c/shelter-animal-outcomes/)\n",
        "\n",
        "Observe that this competition is a **classification task with 5 classes** and, for each item, the model produces a probability for each class. Classes are numbered from 0 to 4.\n",
        "\n",
        "For instance, the following represents the model output for **three items**\n",
        "\n",
        "    [[0.17 0.27 0.03 0.31 0.21]\n",
        "     [0.09 0.44 0.02 0.15 0.3 ]\n",
        "     [0.26 0.18 0.25 0.2  0.11]]\n",
        "     \n",
        "Where the classes with gretest probability assigned by the model are \n",
        "\n",
        "- class 3 for the first item (with 0.31 probability) \n",
        "- class 1 for the second item (with 0.44 probability)\n",
        "- class 0 for the third item (with 0.26 probability)\n",
        "\n",
        "The class labels are expressed as a similar matrix, but with 0/1\n",
        "For instance, the ground truth for the corresponding three items above, could be:\n",
        "\n",
        "    [[0 0 0 1 0]\n",
        "     [0 0 1 0 0]\n",
        "     [1 0 0 0 0]]\n",
        "\n",
        "and will produce a **logloss** of approx 2.14\n",
        "\n",
        "Execute the following cell to generate the data from which you must compute the metric. You may compute the metric implementing python code, or manually, or copy/pasting the actual and predicted data in Excel, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5-nDpABR4at",
        "outputId": "602fe3ef-51d3-4d4c-d349-2294aa63c5a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "actual\n",
            "[[0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 1 0 0]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]]\n",
            "\n",
            "predicted\n",
            "[[0.14 0.22 0.23 0.15 0.26]\n",
            " [0.24 0.21 0.15 0.17 0.23]\n",
            " [0.22 0.25 0.16 0.18 0.2 ]\n",
            " [0.2  0.29 0.11 0.23 0.17]\n",
            " [0.26 0.15 0.16 0.14 0.29]\n",
            " [0.29 0.2  0.12 0.23 0.17]\n",
            " [0.11 0.18 0.19 0.28 0.24]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "t4_predicted = np.random.random(size=(7,5)).T+0.5\n",
        "t4_predicted = np.round((t4_predicted/np.sum(t4_predicted,axis=0)),2).T\n",
        "\n",
        "t4_actual = np.eye(5)[np.random.randint(5,size=len(t4_predicted))].astype(int)\n",
        "\n",
        "print (\"actual\")\n",
        "print (t4_actual)\n",
        "print (\"\\npredicted\")\n",
        "print (t4_predicted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGFIbhoTR4au"
      },
      "source": [
        "Assign the value of your computation to the `logloss` variable **with three decimal places**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idLWc9gWR4av",
        "outputId": "e5e4ad98-76cc-481e-b0f4-7147a667e28b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.534078532827578"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "logloss = log_loss(t4_actual,t4_predicted)\n",
        "logloss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak4Fyut8R4aw"
      },
      "source": [
        "#### submit your answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "g7JvpOe6R4aw"
      },
      "outputs": [],
      "source": [
        "student.submit_task(globals(), task_id=\"task_04\");"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}